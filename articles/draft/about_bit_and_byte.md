# bit(ビット)とByte(バイト)

なんだよその似た言葉は！わかりにくいぞー！！と思っていそうなので…少し説明を試みます。

## bit(ビット)

コンピュータがあつかう最小単位で、０と1で表されます。
1bitだと、0と1なので2種類、2bitだと00、01、10、11の4種類、3bitだと000、001、010、011、100、101、110、111の8種類。2を桁数分だけ掛けた数だけの種類が表現できます。8bitだと256種類のものを表せます。

グラフィック系のソフトを使っている方であれば、24ビットカラーのような表記に馴染みがあるのではないでしょうか。光の3原色の赤緑青に8bitつまり256階調ずつ割り当てて、24bitつまり16,777,216色を表現するものです。

## Byte(バイト)

もともとは複数bitを意味しているもので、データ量、情報量の単位です。
2008年に1Byteは8bitと定義されました。

ファイルサイズやディスク容量などでよく見かけませんか？

### Byteと文字

1Byteは2^8で256種類のものを分けられます。英語のアルファベットは大文字小文字合わせて52種類なので、いろいろな記号を含めたとしても十分表せていて、これをASCII文字として定義しています。SQLを始め、多くのプログラミング言語はASCII文字を基本的に使うようになっています。
一方、日本では日常的に漢字を使っており、その数は第一水準で3000くらい、第二水準までだと6000文字くらいあります。これでは１Byteでは賄えないので、2Byteを使って表現したりしていました。
現在は世界各国の文字に対応できるよう、2Byte以上で一文字を表すようになっています。

## 参考
- [Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%A1%E3%82%A4%E3%83%B3%E3%83%9A%E3%83%BC%E3%82%B8)
  - [ビット](https://ja.wikipedia.org/wiki/%E3%83%93%E3%83%83%E3%83%88)
  - [バイト](https://ja.wikipedia.org/wiki/%E3%83%90%E3%82%A4%E3%83%88_(%E6%83%85%E5%A0%B1))
